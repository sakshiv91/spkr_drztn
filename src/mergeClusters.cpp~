#include "Includes.h" 

//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
//	Global declarations
	string path ;
	int featDim ;
	vvc speechData ;
	int initCluster ;
	int initMixture ;
	string fileName ;
	int numFeats ;
	vvvc clusterData ;
	vi clusterMixtures ;
	int segmentationItr ; 
	vi gmmId ;
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
// read whole speech data in vector of vector of double speechData

void readData(vvc &data, string fileName){
	ifstream infile((fileName).c_str());
	string s;
	stringstream ss;
	int c ;
	vc feature;
	while(getline(infile, s)){
		ss << s;
		double num;
		c = 0;
		fr(i, 0, featDim){
			ss >> num;
			feature.push_back(num);
		}
		//printv(feature, double);
		data.push_back(feature);
		feature.clear();
		cs(ss);
	}
	/*fr(i, 0, data.size()){
		cout << data[i].size() << endl;
	}*/
	//cout << "In data: " << data[0].size() << endl;
}

//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
// Divide equally initial data amongst all the clusters

void initClusters(){
	numFeats = speechData.size();
	int clusterFeatures = numFeats/initCluster ;
	int count = 0;
	vvc temp ;
	fr(i, 0, initCluster){
		do{
			temp.push_back(speechData[count++]);
		}while(count%clusterFeatures != 0);
		clusterData.push_back(temp);
		temp.clear();
	}
	int rem = numFeats - count;
	if(rem > 0.6*clusterFeatures){
		while(count < numFeats){
			temp.push_back(speechData[count++]);
			initCluster++;
		}
		clusterData.push_back(temp);
	}
	else{
		while(count < numFeats){
			clusterData[initCluster-1].push_back(speechData[count++]);
		}
	}
	fr(i, 0, initCluster)
		clusterMixtures.push_back(initMixture);
	tr(clusterMixtures , it)
		cout << *it << " "; 
	fr(i, 0, initCluster)
		gmmId.push_back(i);
}

Ptr<EM> oneGMM(Mat &data, double &llh, int nc){
	Mat labels, logLikelihoods;
	double l1;
	Ptr<EM> gmmmodel = cv::ml::EM::create();
	gmmmodel->setClustersNumber(nc);
    gmmmodel->setCovarianceMatrixType(EM::COV_MAT_DIAGONAL);
	gmmmodel->setTermCriteria(TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 500, 0.01));
	gmmmodel->trainEM( data, logLikelihoods, labels, noArray());
	fr(i, 0, data.size().height){
		llh = llh + logLikelihoods.at<double>(i);
	}
	llh = llh / data.size().height;
	return gmmmodel;
}

void gmmTrain(vector<Ptr<EM>> &gmms, vc &negLogLikelihoods){
	int size = clusterData.size();
	double llh;
	fr(i, 0, size){
		Mat oneClusterData = d2vecToMat(clusterData[i]);
		Ptr<EM> gmm = oneGMM(oneClusterData, llh, clusterMixtures[i]);
		cout << "Cluster " << i << ": " << llh << endl;
		negLogLikelihoods.push_back(llh);
		gmms.push_back(gmm);
	}
}
void segmentation(vector<Ptr<EM>> &gmms){
	vector<int> pollResult(clusterData.size(), 0);
	Mat testFea, prob;
	double llh;
	int max_likelihood = INT_MAX;
	int bestCluster = 0, leader = 0;
	fr(i, 0, clusterData[0].size()){
		testFea = d1VecToMat(clusterData[0][i]);
		fr(j, 0, clusterData.size()){
			llh = (gmms[j] -> predict2(testFea, prob))[0];
			if(llh < max_likelihood ){
				max_likelihood = llh;
				bestCluster = j;
			}
		}
		pollResult[bestCluster]++;
	}
	leader = max_element(pollResult.begin(), pollResult.end());
	
}

//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
int main(int argc, char* argv[]){

//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
//	GOD BLESS US
//	We are assuming we have speech features.
//	Command line arguments
	path = argv[1];
	featDim = ston(argv[2]);
	initCluster = ston(argv[3]);
	fileName = argv[4];
	initMixture = ston(argv[5]);
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	readData(speechData, fileName);
	initClusters();
	vector<Ptr<EM>> gmms;
	vc likelihoods;
	gmmTrain(gmms, likelihoods);
	segmentation(gmms);
}
